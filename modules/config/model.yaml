# model_config.yaml


# Configuration for LLM models used in transcription and summarization.
# 
# Supported Providers:
#   - openai: OpenAI models (gpt-5, gpt-4o, o1, o3, etc.)
#   - anthropic: Anthropic Claude models (claude-3, claude-sonnet, etc.)
#   - google: Google Gemini models (gemini-2.0-flash, gemini-pro, etc.)
#   - openrouter: OpenRouter proxy (access multiple providers via unified API)
#
# Provider Detection:
#   - Explicit: Use "provider:model" format (e.g., "openai:gpt-5-mini")
#   - Automatic: Provider inferred from model name prefixes (gpt- = openai, claude- = anthropic, etc.)
#
# API Keys (set as environment variables):
#   - OPENAI_API_KEY: For OpenAI models
#   - ANTHROPIC_API_KEY: For Anthropic models
#   - GOOGLE_API_KEY: For Google Gemini models
#   - OPENROUTER_API_KEY: For OpenRouter proxy

transcription_model:
  # Model configuration for image transcription
  name: "gpt-5.2"  # Model identifier (use "provider:model" for explicit provider)
  provider: "openai"  # Provider: openai, anthropic, google, openrouter (optional if using prefix)
  max_output_tokens: 16000  # Maximum output token budget
  
  # Cross-provider reasoning controls
  # Maps to provider-native implementations:
  #   - OpenAI GPT-5/o-series: reasoning_effort parameter
  #   - Anthropic Claude 4.5+: extended thinking (budget_tokens: low=1024, medium=4096, high=16384)
  #   - Google Gemini 2.5+/3: thinking_level (low="low", medium/high="high")
  reasoning:
    effort: medium  # Options: low, medium, high
  
  # OpenAI-specific text verbosity (GPT-5 family only)
  text:
    verbosity: medium  # Options: low, medium, high
  
  # Provider-agnostic parameters
  temperature: 1.0  # null = use provider default; 0.0-2.0 for explicit control

summary_model:
  # Model configuration for text summarization
  name: "gpt-5-mini"  # Model identifier (use "provider:model" for explicit provider)
  provider: "openai"  # Provider: openai, anthropic, google, openrouter (optional if using prefix)
  max_output_tokens: 16384  # Maximum output token budget
  
  # Cross-provider reasoning controls (see transcription_model for details)
  reasoning:
    effort: medium  # Options: low, medium, high
  
  # OpenAI-specific text verbosity (GPT-5 family only)
  text:
    verbosity: low  # Options: low, medium, high (low for more concise summaries)
  
  # Provider-agnostic parameters
  temperature: 1.0  # null = use provider default; 0.0-2.0 for explicit control

# Example configurations for other providers:
#
# Anthropic Claude 4.5 (with extended thinking):
#   transcription_model:
#     name: "claude-sonnet-4-5-20250929"
#     provider: "anthropic"
#     max_output_tokens: 16384
#     reasoning:
#       effort: medium  # Maps to budget_tokens: 4096
#     temperature: 1.0  # Required for extended thinking
#
# Google Gemini 2.5 (with thinking mode):
#   transcription_model:
#     name: "gemini-2.5-flash"
#     provider: "google"
#     max_output_tokens: 32768
#     reasoning:
#       effort: high  # Maps to thinking_level: "high"
#     temperature: 0.0
#
# Google Gemini 2.0 (no thinking mode):
#   transcription_model:
#     name: "gemini-2.0-flash"
#     provider: "google"
#     max_output_tokens: 8192
#     temperature: 0.0
#
# OpenRouter (access any model):
#   transcription_model:
#     name: "anthropic/claude-sonnet-4-5"
#     provider: "openrouter"
#     max_output_tokens: 8192
#     reasoning:
#       effort: medium
