# =============================================================================
# Image Processing Configuration
# =============================================================================
# Controls image preprocessing before LLM API calls and text post-processing.
# Loaded by: modules/image_utils.py, modules/text_cleaner.py
#
# Each provider has different optimal resizing strategies that affect both
# quality and token costs. The correct section is auto-selected based on
# the configured provider and model name.
#
# Related config files:
#   - app.yaml: Application settings and feature toggles
#   - model.yaml: LLM provider and model settings
#   - concurrency.yaml: API rate limits and parallelism

# =============================================================================
# OpenAI API Image Processing
# =============================================================================
# Preprocessing for OpenAI models (GPT-5, GPT-4o, o-series, etc.)
# Uses tiling approach with 512x512 tiles for 'high' detail
# Token cost: low=85 tokens; high=85 + (170 × number of 512px tiles)
api_image_processing:
  target_dpi: 300  # PDF rendering resolution
  grayscale_conversion: true  # Convert to grayscale (improves OCR)
  handle_transparency: true   # Flatten alpha channel onto white background
  
  # Controls fidelity sent to OpenAI Vision API:
  # - high: uses tiling (170 tokens per 512×512 tile), better for fine details
  # - low: 512×512 resize, 85 tokens per image, faster/cheaper
  # - auto: omit parameter, let model decide
  llm_detail: high
  
  jpeg_quality: 100  # JPEG compression (1-100)
  
  # Resize strategy: 'high' | 'low' | 'auto' | 'none'
  resize_profile: high
  
  # Resize parameters
  low_max_side_px: 512         # Max dimension for 'low' profile
  high_target_box: [768, 1536] # [width, height] box for 'high' profile (with padding)


# =============================================================================
# Google Gemini API Image Processing
# =============================================================================
# Preprocessing for Google Gemini models (Gemini 3, 2.5, 2.0, 1.5)
# Google uses 768x768 tiles for token calculation
# Token counts (Gemini 3): ultra_high=2240, high=1120, medium=560, low=280
google_image_processing:
  target_dpi: 300  # PDF rendering resolution
  grayscale_conversion: true  # Convert to grayscale (improves OCR)
  handle_transparency: true   # Flatten alpha channel onto white background
  
  # Controls resolution sent to Google Gemini API (media_resolution enum):
  # - ultra_high: 2240 tokens - Highest quality (per-part only)
  # - high: 1120 tokens - Recommended for OCR/dense documents
  # - medium: 560 tokens - Balanced quality/cost
  # - low: 280 tokens - Minimal tokens, fast/cheap
  # - auto: Default (1120 for images, 560 for PDFs)
  media_resolution: high
  
  jpeg_quality: 100  # JPEG compression (1-100)
  
  # Resize strategy: 'high' | 'low' | 'auto' | 'none'
  # Google's token calculation uses 768x768 tiles, so we optimize for that
  resize_profile: high
  
  # Resize parameters
  low_max_side_px: 512         # Max dimension for 'low' profile
  high_target_box: [768, 1536] # [width, height] box optimized for 768px tiles


# =============================================================================
# Anthropic Claude API Image Processing
# =============================================================================
# Preprocessing for Anthropic Claude models (Claude 4.5, 4, 3.x)
# Anthropic recommends: long edge ≤ 1568px, ≤ 1.15 megapixels for optimal latency
# Min 200px on any edge; max 8000×8000px
# Token calculation: tokens = (width × height) / 750
# Example: 1568×1568 ≈ 3,276 tokens; 1024×1024 ≈ 1,398 tokens
# Anthropic auto-resizes images >1568px (increases latency without benefit)
anthropic_image_processing:
  target_dpi: 300  # PDF rendering resolution
  grayscale_conversion: true  # Convert to grayscale (improves OCR)
  handle_transparency: true   # Flatten alpha channel onto white background
  
  jpeg_quality: 100  # JPEG compression (1-100)
  
  # Resize strategy: 'high' | 'low' | 'auto' | 'none'
  # Unlike OpenAI/Google, Anthropic uses simple max-side capping (no padding)
  # Best practice: pre-resize to ≤1568px to avoid server-side resizing latency
  resize_profile: auto
  
  # Resize parameters (Anthropic uses max-side capping, no box fitting)
  low_max_side_px: 512   # Max dimension for 'low' profile
  high_max_side_px: 1568 # Max dimension for 'high' profile (Anthropic's optimal)


# =============================================================================
# Text Cleaning Configuration
# =============================================================================
# Post-processing for transcription text before summarization and output.
# Fixes common OCR artifacts while preserving semantic content.

text_cleaning:
  enabled: true  # Master switch for all text cleaning
  
  # ---------------------------------------------------------------------------
  # Unicode Normalization
  # ---------------------------------------------------------------------------
  # NFC normalization, removes control chars, soft hyphens, zero-width spaces
  unicode_normalization: true
  
  # ---------------------------------------------------------------------------
  # LaTeX Formula Fixing
  # ---------------------------------------------------------------------------
  # Repairs common OCR errors in mathematical notation
  latex_fixing:
    enabled: true
    balance_dollar_signs: true   # Fix unbalanced $ and $$ delimiters
    close_unclosed_braces: true  # Close orphan { in LaTeX commands
    fix_common_commands: true    # Fix typos like "\frac {" -> "\frac{"
  
  # ---------------------------------------------------------------------------
  # Hyphenation Merging
  # ---------------------------------------------------------------------------
  # Rejoins words split at line breaks: "politi-\nche" -> "politiche"
  # WARNING: Can damage genuine compounds like "Jean-Baptiste"
  merge_hyphenation: false  # Disabled by default - enable for scanned books
  
  # ---------------------------------------------------------------------------
  # Whitespace Normalization
  # ---------------------------------------------------------------------------
  whitespace_normalization:
    enabled: true
    collapse_internal_spaces: true  # 3+ spaces -> 2 spaces
    max_blank_lines: 2              # Remove excess blank lines
    tab_size: 4                     # Spaces per tab when expanding
  
  # ---------------------------------------------------------------------------
  # Line Wrapping
  # ---------------------------------------------------------------------------
  # Wrap excessively long lines (usually not needed for LLM output)
  line_wrapping:
    enabled: true
    auto_width: false   # Compute width from text statistics
    fixed_width: 120    # Used if auto_width is false
